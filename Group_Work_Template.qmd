---
bibliography: bio.bib
csl: harvard-cite-them-right.csl
title: Group Name's Group Project
execute:
  echo: false
  freeze: true
format:
  html:
    code-copy: true
    code-link: true
    toc: true
    toc-title: On this page
    toc-depth: 2
    toc_float:
      collapsed: false
      smooth_scroll: true
  pdf:
    include-in-header:
      text: |
        \addtokomafont{disposition}{\rmfamily}
    mainfont: Spectral
    sansfont: Roboto Flex
    monofont: InputMonoCondensed
    papersize: a4
    geometry:
      - top=25mm
      - left=40mm
      - right=30mm
      - bottom=25mm
      - heightrounded
    toc: false
    number-sections: false
    colorlinks: true
    highlight-style: github
jupyter:
  jupytext:
    text_representation:
      extension: .qmd
      format_name: quarto
      format_version: '1.0'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: Python (base)
    language: python
    name: base
---

```{python}
#| echo: false
import os
import numpy as np
import pandas as pd
import geopandas as gpd
import requests
import zipfile
import matplotlib.cm as cm
import matplotlib.pyplot as plt
from scipy.spatial.distance import pdist, squareform
from scipy.cluster.hierarchy import fcluster, linkage
from dateutil.relativedelta import relativedelta
from datetime import datetime
from PIL import Image
from io import BytesIO
from shapely.geometry import Point
from urllib.parse import urlparse

pd.set_option('display.max_columns', None)
pd.options.display.max_colwidth = 200
```

```{python}
dest = os.path.join('data','raw') #destination to save data
src  = f"https://data.insideairbnb.com/united-kingdom/england/london/2024-09-06/data/listings.csv.gz"
url = urlparse(src) # We assume that this is some kind of valid URL 
fn = (url.path.split('/')[-3])+(url.path.split('/')[-1]) # return the file name with date
os.path.split(url.path)[-1]
dfn = os.path.join(dest,fn) # Destination filename
print(f"Writing to: {fn}")
```

```{python}
dfn
```

```{python}
if not os.path.isfile(dfn) or os.stat(dfn).st_size < 250:
    
    print(f"{dfn} not found or corrupted, downloading!")
    path = os.path.split(dest)
    if len(path) >= 1 and path[0] != '':
        os.makedirs(os.path.join(*path), exist_ok=True)
        # Download and save the file
        try:
            with open(dfn, "wb") as file:
                response = get(src)
                response.raise_for_status()  # Raise an exception for HTTP errors
                file.write(response.content)
            print("\tDone downloading.")
        except Exception as e:
            print(f"Error while downloading {src}: {e}")
            return ""
 
    print("\tDone downloading.")
    f_size = os.stat(dfn).st_size
    print(f"\tSize is {f_size/1024**2:,.0f} MB ({f_size:,} bytes)")
else:
    print(f"Found {dfn} locally!")
    f_size = os.stat(dfn).st_size
    print(f"\tSize is {f_size/1024**2:,.0f} MB ({f_size:,} bytes)")
```

```{python}
#| echo: false
def cache_data(src:str) -> str:
    """Downloads and caches a remote file locally.
    src : str - The remote *source* for the file, any valid URL should work.
    dest : str - The *destination* location to save the downloaded file.    
    Returns a string representing the local location of the file.
    """
    dest = os.path.join('data','raw') #destination to save data
    
    url = urlparse(src) # We assume that this is some kind of valid URL 
    fn = (url.path.split('/')[-3])+(url.path.split('/')[-1]) # return the file name with date
    dfn = os.path.join(dest,fn) # Destination filename
    print(f"Writing to: {fn}")

    if not os.path.isfile(dfn) or os.stat(dfn).st_size < 250:
        
        print(f"{dfn} not found or corrupted, downloading!")
        path = os.path.split(dest)
        if len(path) >= 1 and path[0] != '':
            os.makedirs(os.path.join(*path), exist_ok=True)
            # Download and save the file #os.path.join(*path)
            try:
                with open(dfn, "wb") as file:
                    response = get(src)
                    response.raise_for_status()  # Raise an exception for HTTP errors
                    file.write(response.content)
                print("\tDone downloading.")
            except Exception as e:
                print(f"Error while downloading {src}: {e}")
                return ""
     
        print("\tDone downloading.")
        f_size = os.stat(dfn).st_size
        print(f"\tSize is {f_size/1024**2:,.0f} MB ({f_size:,} bytes)")
    else:
        print(f"Found {dfn} locally!")
        f_size = os.stat(dfn).st_size
        print(f"\tSize is {f_size/1024**2:,.0f} MB ({f_size:,} bytes)")
        
    return dfn
```

```{python}
#| echo: false
# Set download URL for London data the date should be choosen by reviewing 
# the Inside Airbnb Get Data page and identifying the date of the required data
airbnbdates  = ["2023-12-10", "2024-09-06"]
airbnbcols = ['id', 'listing_url', 'picture_url', 'host_id', 'host_listings_count',
              'host_total_listings_count', 'property_type', 'room_type', 'price', 
              'minimum_nights', 'maximum_nights', 'availability_365', 
              'number_of_reviews', 'latitude', 'longitude', 'last_review', 
              'beds', 'bedrooms']
airbnbdfs = []

for date in airbnbdates:
    airbnburl  = f"https://data.insideairbnb.com/united-kingdom/england/london/{date}/data/listings.csv.gz"
    dfn = cache_data(airbnburl)
    airbnbdfs.append(pd.read_csv(dfn, low_memory=False,usecols=airbnbcols))
    #.split('/')[-1]
    print(f"Data frame from date {date} is {df.shape[0]:,} x {df.shape[1]}")

airbnb_old, airbnb2024_new = airbnbdfs
```

```{python}
dfn
```


## 1. Who collected the InsideAirbnb data?

::: {.duedate}

( 2 points; Answer due Week 7 )

:::

An inline citation example: As discussed on @insideairbnb, there are many...

A parenthetical citation example: There are many ways to research Airbnb [see, for example, @insideairbnb]... 

## 2. Why did they collect the InsideAirbnb data?

::: {.duedate}

( 4 points; Answer due Week 7 )

:::

```{python}
#| output: asis
print(f"One of way to embed output in the text looks like this: after cleaning, we were left with {df.shape[0]:,} rows of data.")
```

This way is also supposed to work (`{python} f"{df.shape[0]:,}" `) but I've found it less reliable.

```{python}
ax = df.host_listings_count.plot.hist(bins=50);
ax.set_xlim([0,500]);
```

## 3. How was the InsideAirbnb data collected?  

::: {.duedate}

( 5 points; Answer due Week 8 )

:::

## 4. How does the method of collection impact the completeness and/or accuracy of the InsideAirbnb data set's representation of the process it seeks to study, and what wider issues does this raise?

::: {.duedate}

( 11 points; Answer due Week 9 )

:::

## 5. What ethical considerations does the use of the InsideAirbnb data raise? 

::: {.duedate}

( 18 points; Answer due {{< var assess.group-date >}} )

:::

## 6. With reference to the InsideAirbnb data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? 

::: {.duedate}

( 15 points; Answer due {{< var assess.group-date >}} )

:::

## 7. Drawing on your previous answers, and supporting your response with evidence (*e.g.* figures, maps, EDA/ESDA, and simple statistical analysis/models drawing on experience from, e.g., CASA0007), how *could* the InsideAirbnb data set be used to inform the regulation of Short-Term Lets (STL) in London? 

::: {.duedate}

( 45 points; Answer due {{< var assess.group-date >}} )

:::

## Sustainable Authorship Tools

Using the Terminal in Docker, you compile the Quarto report using `quarto render <group_submission_file>.qmd`.

Your QMD file should automatically download your BibTeX and CLS files and any other required files. If this is done right after library loading then the entire report should output successfully.

Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style="font-family:Sans-Serif;">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). 

## References

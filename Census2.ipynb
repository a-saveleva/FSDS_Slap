{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "682f9261-dcb4-4b8d-9f64-6f25ded229ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da31a7a-3383-431d-9ac3-b7c0b69da9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to remove spaces from column names\n",
    "#df.columns = df.columns.str.replace(' ', '_')\n",
    "\n",
    "\n",
    "#code for deleting redundant data frames\n",
    "#>>> lst = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]\n",
    "#>>> del lst     # memory is released\n",
    "\n",
    "\n",
    "#code for merging multiple dataframes\n",
    "#from functools import reduce\n",
    "#dfs = [df1, df2, df3, df4, df5, df6]\n",
    "#df_final = reduce(lambda left,right: pd.merge(left,right,on='some_common_column_name'), dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9edfa35-36a0-45e1-8565-9b7cdd1b0a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN LSOA DWELLINGS FROM CENSUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c9953d-6ca1-41dc-a488-b35f935dd7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusLSOAdwell = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_LSOA_Dwellings.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 4994)\n",
    "#df_censusLSOAdwell.shape\n",
    "#df_censusLSOAdwell.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818aba50-28cc-40db-902e-6eec023df007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f9900-10ef-4034-80f0-dd81df71fabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e959151-4e91-4649-ae10-403ad0c05279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN BOROUGH LEVEL CENSUS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ccc9c2-6966-4cac-a7c3-b09a55fbfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusdwellings = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_dwellings.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['local authority: county / unitary (as of April 2023)',\n",
    "                                                                       'mnemonic', 'Total'])\n",
    "\n",
    "df_censusdwellings.rename(columns={'local authority: county / unitary (as of April 2023)':'LAName'}, inplace = True)\n",
    "df_censusdwellings.rename(columns={'Total':'Total_Dwellings'}, inplace = True)\n",
    "\n",
    "#df_censusdwellings.shape\n",
    "#df_censusdwellings.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637de21-817a-435b-b28a-f6b093c28141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f949371-1a90-4b91-a542-ff5253e0b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN BOROUGH LEVEL HHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee71bd3f-e636-47eb-a82c-4b77a17ecc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusHHolds = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_Households.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', '2021'])\n",
    "\n",
    "df_censusHHolds.rename(columns={'2021':'Total_Hholds'}, inplace = True)\n",
    "\n",
    "#df_censusHHolds.shape\n",
    "#df_censusHHolds.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d3bdb-e13a-4edf-a6f1-566493cbcef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d80fb48c-75ac-4114-88bb-c5ad613bcd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN BOROUGH TENURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ebd72b-0ab2-486c-9ced-a69aae8163fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_censusTenure \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_Tenure.csv?raw=true\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m33\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnemonic\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOwned\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mShared ownership\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSocial rented\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrivate rented or lives rent free\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df_censusTenure\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      7\u001b[0m df_censusTenure\u001b[38;5;241m.\u001b[39mdtypes\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "df_censusTenure = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_Tenure.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'Owned', 'Shared ownership',\n",
    "                                                                      'Social rented', \n",
    "                                                                       'Private rented or lives rent free'])\n",
    "\n",
    "df_censusTenure.shape\n",
    "df_censusTenure.dtypes\n",
    "\n",
    "p_tenure = [df_censusTenure['Owned'],df_censusTenure['Shared ownership'],df_censusTenure['Social rented'],\n",
    "            df_censusTenure['Private rented or lives rent free']]\n",
    "\n",
    "df_censusTenure[\"Tenure_entropy\"] = entropy(p_tenure, base=2)\n",
    "#df_censusTenure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623c750-c2a7-4a1f-b058-ef68fe692d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8506896-0669-4e43-a0d9-f278943b44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusaccomm = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_Accommodation.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'Detached', 'Semi-detached',\n",
    "                                  'Terraced', 'In a purpose-built block of flats or tenement',\n",
    "                                  'Part of a converted or shared house, including bedsits', \n",
    "                                  'Part of another converted building, for example, former school, church or warehouse',\n",
    "                                  'In a commercial building, for example, in an office building, hotel or over a shop'])\n",
    "df_censusaccomm.shape\n",
    "df_censusaccomm.dtypes\n",
    "\n",
    "p_accomm = [df_censusaccomm['Detached'],df_censusaccomm['Semi-detached'],df_censusaccomm['Terraced'],df_censusaccomm['In a purpose-built block of flats or tenement'],\n",
    "           df_censusaccomm['Part of a converted or shared house, including bedsits'],df_censusaccomm['Part of another converted building, for example, former school, church or warehouse'],\n",
    "            df_censusaccomm['In a commercial building, for example, in an office building, hotel or over a shop']]\n",
    "\n",
    "df_censusaccomm[\"Accommm_entropy\"] = entropy(p_accomm, base=2)\n",
    "#df_censusaccomm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6d5d7-ea5a-4fc2-b660-8a50360aa4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313e23f6-086b-4851-b03c-4df6d239b74b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b9606c-7c9e-41a0-b4c6-64e0041c66ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43a70090-0504-486e-8bda-db22d25a33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusbedocc = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_BedroomOcc.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'Occupancy rating of bedrooms: +2 or more',\n",
    "                                                                       'Occupancy rating of bedrooms: +1',\n",
    "                                                                       'Occupancy rating of bedrooms: 0',\n",
    "                                                                       'Occupancy rating of bedrooms: -1',\n",
    "                                                                       'Occupancy rating of bedrooms: -2 or less'])\n",
    "df_censusbedocc.shape\n",
    "df_censusbedocc.dtypes\n",
    "\n",
    "p_bedocc = [df_censusbedocc['Occupancy rating of bedrooms: +2 or more'],df_censusbedocc['Occupancy rating of bedrooms: +1'],\n",
    "            df_censusbedocc['Occupancy rating of bedrooms: 0'],df_censusbedocc['Occupancy rating of bedrooms: -1'],\n",
    "            df_censusbedocc['Occupancy rating of bedrooms: -2 or less']]\n",
    "\n",
    "df_censusbedocc[\"Bedocc_entropy\"] = entropy(p_bedocc, base=2)\n",
    "#df_censusbedocc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69ea02be-7843-4541-873a-cc0ff1ce6818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censuscarsvans = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_CarsVans.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'No cars or vans in household',\n",
    "                                                                       '1 car or van in household', '2 cars or vans in household',\n",
    "                                                                       '3 or more cars or vans in household'])\n",
    "df_censuscarsvans.shape\n",
    "df_censuscarsvans.dtypes\n",
    "\n",
    "p = [df_censuscarsvans['No cars or vans in household'], df_censuscarsvans['1 car or van in household'], df_censuscarsvans['2 cars or vans in household'],\n",
    "     df_censuscarsvans['3 or more cars or vans in household']]\n",
    "df_censuscarsvans[\"Cars_entropy\"] = entropy(p, base=2)\n",
    "\n",
    "#https://www.geeksforgeeks.org/how-to-compute-entropy-using-scipy/\n",
    "\n",
    "\n",
    "#df_censuscarsvans[\"TestVar\"] = df_censuscarsvans['No cars or vans in household']\n",
    "#df_censuscarsvans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce99259f-1d4c-4a65-8a41-81c7cf2df754",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusdepriv = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_Deprivation.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'Household is not deprived in any dimension',\n",
    "                                                                       'Household is deprived in one dimension',\n",
    "                                                                       'Household is deprived in two dimensions',\n",
    "                                                                       'Household is deprived in three dimensions',\n",
    "                                                                       'Household is deprived in four dimensions'])\n",
    "df_censusdepriv.shape\n",
    "df_censusdepriv.dtypes\n",
    "\n",
    "p_depriv = [df_censusdepriv['Household is not deprived in any dimension'],df_censusdepriv['Household is deprived in one dimension'],\n",
    "            df_censusdepriv['Household is deprived in two dimensions'], df_censusdepriv['Household is deprived in three dimensions'],\n",
    "            df_censusdepriv['Household is deprived in four dimensions']]\n",
    "\n",
    "df_censusdepriv[\"Depriv_entropy\"] = entropy(p_depriv, base=2)\n",
    "#df_censusdepriv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9488710e-2a02-49bc-bb19-a646391aea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusnssec = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_NsSeC.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'L1, L2 and L3 Higher managerial, administrative and professional occupations',\n",
    "                                                                       'L4, L5 and L6 Lower managerial, administrative and professional occupations',\n",
    "                                                                       'L7 Intermediate occupations', 'L8 and L9 Small employers and own account workers',\n",
    "                                                                       'L10 and L11 Lower supervisory and technical occupations',\n",
    "                                                                       'L12 Semi-routine occupations', 'L13 Routine occupations',\n",
    "                                                                       'L14.1 and L14.2 Never worked and long-term unemployed',\n",
    "                                                                       'L15 Full-time students'])\n",
    "df_censusnssec.shape\n",
    "df_censusnssec.dtypes\n",
    "\n",
    "p_nssec = [df_censusnssec['L1, L2 and L3 Higher managerial, administrative and professional occupations'],\n",
    "           df_censusnssec['L4, L5 and L6 Lower managerial, administrative and professional occupations'],\n",
    "          df_censusnssec['L7 Intermediate occupations'],df_censusnssec['L8 and L9 Small employers and own account workers'],\n",
    "          df_censusnssec['L10 and L11 Lower supervisory and technical occupations'],df_censusnssec['L12 Semi-routine occupations'],\n",
    "          df_censusnssec['L13 Routine occupations'],df_censusnssec['L14.1 and L14.2 Never worked and long-term unemployed'],\n",
    "          df_censusnssec['L15 Full-time students']]\n",
    "\n",
    "df_censusnssec[\"NsSEC_entropy\"] = entropy(p_nssec, base=2)\n",
    "#df_censusnssec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac58068-d298-48d1-bade-130adc8c50e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mnemonic       object\n",
       "PopDensity    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_censuspopdens = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_PopDensity.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33 ,usecols = ['mnemonic', '2021'])\n",
    "\n",
    "df_censuspopdens.rename(columns={'2021':'PopDensity'}, inplace=True)\n",
    "\n",
    "df_censuspopdens.shape\n",
    "df_censuspopdens.dtypes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3beb8ee2-3154-48bd-966a-e6a6992ae204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_censusaddress = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/census_data/Census_Addresses.csv?raw=true\", \n",
    "                                  skiprows = 6, nrows = 33, usecols = ['mnemonic', 'Address one year ago is the same as the address of enumeration',\n",
    "                                                                      'Address one year ago is student term-time or boarding school address in the UK',\n",
    "                                                                      'Migrant from within the UK: Address one year ago was in the UK',\n",
    "                                                                      'Migrant from outside the UK: Address one year ago was outside the UK'])\n",
    "df_censusaddress.shape\n",
    "df_censusaddress.dtypes\n",
    "\n",
    "p_address = [df_censusaddress['Address one year ago is the same as the address of enumeration'],\n",
    "             df_censusaddress['Address one year ago is student term-time or boarding school address in the UK'],\n",
    "            df_censusaddress['Migrant from within the UK: Address one year ago was in the UK'],\n",
    "             df_censusaddress['Migrant from outside the UK: Address one year ago was outside the UK']]\n",
    "\n",
    "df_censusaddress[\"Address_entropy\"] = entropy(p_address, base=2)\n",
    "#df_censusaddress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e10310-e076-42e3-ac34-72645989142c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c73a747-1a6c-4402-957e-11a3373acaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN VACANT HOMES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0035189-4f16-4892-938e-10c413a8ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.london.gov.uk/download/vacant-dwellings/c428a18b-9961-4b98-9cfe-b7f120114141/vacant-dwellings-borough%20%282%29.xlsx\n",
    "df_vacantprops = pd.read_excel(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/vacant-dwellings-borough.xlsx?raw=true\", \n",
    "                                  sheet_name = 2, skiprows = 1, nrows = 34, usecols = [0,21])\n",
    "\n",
    "df_vacantprops.dropna(inplace = True)\n",
    "#df_vacantprops.shape\n",
    "\n",
    "\n",
    "#column_names = list(df_vacantprops.columns)\n",
    "#print(column_names)\n",
    "\n",
    "df_vacantprops.rename(columns={'Unnamed: 0':'mnemonic'}, inplace=True)\n",
    "df_vacantprops.rename(columns={2023:'2023_LTVacant'}, inplace=True)\n",
    "\n",
    "#df_vacantprops.dtypes\n",
    "\n",
    "#print(df_vacantprops)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd0341-e430-47de-b270-7117a282c047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71a2b92a-6803-4f45-9471-a597ec39325e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN MEDIAN HOUSE PRIVATE VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b391ea3-718a-473d-9d4f-1f75ccf35062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/hpssadataset9medianpricepaidforadministrativegeographies.xls\n",
    "\n",
    "df_hp_median = pd.read_excel(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/hpssadataset9medianpricepaidforadministrativegeographies.xls?raw=true\", \n",
    "                                  sheet_name = 10, skiprows = 6, nrows = 331, usecols = [2,113])\n",
    "#df_hp_median.shape\n",
    "#df_hp_median.dtypes\n",
    "\n",
    "#column_names = list(df_hp_median.columns)\n",
    "#print(column_names)\n",
    "\n",
    "df_hp_median.rename(columns={'Local authority code ':'mnemonic'}, inplace=True)\n",
    "df_hp_median.rename(columns={'Year ending Mar 2023':'MedianHP_2023'}, inplace=True)\n",
    "\n",
    "df_median_London = df_hp_median[df_hp_median['mnemonic'].str.startswith('E09')]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(df_median_London.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0fbe5f-e2f2-4554-b3aa-e91dacc52cb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63949baf-7213-4af9-9cbe-c830cd343bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD IN LOWER QUARTILE HOUSE PRIVATE VALUES\n",
    "#https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/hpssadataset15lowerquartilepricepaidforadministrativegeographies.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dfc6a4d-fd87-4da9-8063-fc1bee154d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp_lower = pd.read_excel(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/hpssadataset15lowerquartilepricepaidforadministrativegeographies.xls?raw=true\", \n",
    "                                  sheet_name = 10, skiprows = 6, nrows = 331, usecols = [2,113])\n",
    "#df_hp_lower.shape\n",
    "#df_hp_lower.dtypes\n",
    "\n",
    "#column_names = list(df_hp_lower.columns)\n",
    "#print(column_names)\n",
    "\n",
    "df_hp_lower.rename(columns={'Local authority code ':'mnemonic'}, inplace=True)\n",
    "df_hp_lower.rename(columns={'Year ending Mar 2023':'LowerQHP_2023'}, inplace=True)\n",
    "\n",
    "df_lower_London = df_hp_lower[df_hp_lower['mnemonic'].str.startswith('E09')]\n",
    "\n",
    "#print(df_lower_London.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb2a468-2840-4d79-9ec7-83fd98640065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfd09e7-9395-4741-a8e2-4a12ce83a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD SALES DATA\n",
    "#https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/Sales-2024-09.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32747e83-090f-47ce-aec5-b41a87ebe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp_sales = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/Sales-2024-09.csv?raw=true\", \n",
    "                                  skiprows = 0, nrows = 138543, parse_dates = ['Date'])\n",
    "df_hp_sales.shape\n",
    "df_hp_sales.dtypes\n",
    "\n",
    "df_hp_sales.rename(columns={'Area_Code':'mnemonic'}, inplace=True)\n",
    "df_sales_London = df_hp_sales[df_hp_sales['mnemonic'].str.startswith('E09')]\n",
    "\n",
    "df_hp_sales_filt = df_sales_London.query(\"Date >= '2023-04-01' and Date < '2024-03-31'\")\n",
    "df_hp_totals = df_hp_sales_filt.groupby(['mnemonic']).sum(['Sales_Volume'])\n",
    "\n",
    "\n",
    "\n",
    "#column_names = list(df_hp_sales.columns)\n",
    "#print(column_names)\n",
    "\n",
    "\n",
    "#print(df_sales_London.head())\n",
    "#df_sales_London.dtypes\n",
    "#df_hp_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23dff1c-59fe-400f-be33-02d99451cef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66e29a43-a25a-418c-916c-a8911af2c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD FIRST TIME BUYERS\n",
    "#https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/First-Time-Buyer-Former-Owner-Occupied-2024-09.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09da06f8-5a2d-4f4b-b72c-0aab8bc3dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp_firsttime = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/First-Time-Buyer-Former-Owner-Occupied-2024-09.csv?raw=true\", \n",
    "                                  skiprows = 0, nrows = 60219, parse_dates = ['Date'],\n",
    "                             usecols = ['Date', 'Area_Code', 'First_Time_Buyer_Average_Price', 'Former_Owner_Occupier_Average_Price'])\n",
    "df_hp_firsttime.shape\n",
    "df_hp_firsttime.dtypes\n",
    "\n",
    "df_hp_firsttime.rename(columns={'Area_Code':'mnemonic'}, inplace=True)\n",
    "df_hp_firsttime_London = df_hp_firsttime[df_hp_firsttime['mnemonic'].str.startswith('E09')]\n",
    "\n",
    "df_hp_firsttime_London_filt = df_hp_firsttime_London.query(\"Date >= '2023-04-01' and Date < '2024-03-31'\")\n",
    "\n",
    "df_hp_firsttime_London_totals = df_hp_firsttime_London_filt.groupby(['mnemonic']).mean(['First_Time_Buyer_Average_Price', 'Former_Owner_Occupier_Average_Price'])\n",
    "\n",
    "#column_names = list(df_hp_firsttime.columns)\n",
    "#print(column_names)\n",
    "\n",
    "\n",
    "#print(df_hp_firsttime_London_totals.head())\n",
    "#df_firsttime_London.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33081208-113e-42b2-a1d8-4897726a870f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efccc02f-422f-4799-b5a5-8c6a9df14d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD NEW BUILD\n",
    "#https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/New-and-Old-2024-09.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "514f8d83-3b89-434d-a20a-5fce149ebc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hp_newbuild = pd.read_csv(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/house_prices/New-and-Old-2024-09.csv?raw=true\", \n",
    "                                  skiprows = 0, nrows = 138543, parse_dates = ['Date'],\n",
    "                            usecols = ['Date', 'Area_Code', 'New_Build_Average_Price','Existing_Property_Average_Price'])\n",
    "df_hp_newbuild.shape\n",
    "df_hp_newbuild.dtypes\n",
    "\n",
    "df_hp_newbuild.rename(columns={'Area_Code':'mnemonic'}, inplace=True)\n",
    "df_hp_newbuild_London = df_hp_newbuild[df_hp_newbuild['mnemonic'].str.startswith('E09')]\n",
    "\n",
    "df_hp_newbuild_London_filt = df_hp_newbuild_London.query(\"Date >= '2023-04-01' and Date < '2024-03-31'\")\n",
    "\n",
    "df_hp_newbuild_London_London_totals = df_hp_newbuild_London_filt.groupby(['mnemonic']).mean(['New_Build_Average_Price', 'Existing_Property_Average_Price'])\n",
    "\n",
    "#column_names = list(df_hp_newbuild.columns)\n",
    "#print(column_names)\n",
    "\n",
    "#df_newbuild_London = df_hp_newbuild[df_hp_newbuild['Area_Code'].str.startswith('E09')]\n",
    "#print(df_hp_newbuild_London_London_totals.head())\n",
    "#df_newbuild_London.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc62f00-1df4-460b-9b0b-ad48654d6585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903cd2ff-e48f-4235-b0d4-6797962368af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5eb7fc83-8b4d-4657-8fe0-348897adebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD IN HOMELESSNESS DATA\n",
    "#https://github.com/a-saveleva/FSDS_Slap/blob/main/homelessness/Detailed_LA_20232024.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b97c4a89-341d-4568-a549-72ffde975486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_homless_A2P = pd.read_excel(\"https://github.com/a-saveleva/FSDS_Slap/blob/main/homelessness/Detailed_LA_20232024.xlsx?raw=true\", \n",
    "                                  sheet_name = 3, skiprows = 7, nrows = 310, header = None, usecols=[0,4,6,16])\n",
    "\n",
    "df_homless_A2P.rename(columns={0:'mnemonic'}, inplace = True)\n",
    "df_homless_A2P.rename(columns={4:'HHoldsPrevDuty'}, inplace = True)\n",
    "df_homless_A2P.rename(columns={6:'HHoldEndAST'}, inplace = True)\n",
    "df_homless_A2P.rename(columns={16:'HHoldSellRelet'}, inplace = True)\n",
    "\n",
    "df_homless_A2P['HHoldsPrevDuty'] = pd.to_numeric(df_homless_A2P['HHoldsPrevDuty'], errors='coerce')\n",
    "df_homless_A2P['HHoldEndAST'] = pd.to_numeric(df_homless_A2P['HHoldEndAST'], errors='coerce')\n",
    "df_homless_A2P['HHoldSellRelet'] = pd.to_numeric(df_homless_A2P['HHoldSellRelet'], errors='coerce')\n",
    "\n",
    "#df_homless_A2P.shape\n",
    "#df_homless_A2P.dtypes\n",
    "\n",
    "df_homless_A2P.dropna(how='all', axis=1, inplace=True) \n",
    "df_homless_A2P.dropna(how='all', axis=0, inplace=True) \n",
    "\n",
    "#column_names = list(df_homless_A2P.columns)\n",
    "#print(column_names)\n",
    "\n",
    "df_homless_A2P_London = df_homless_A2P[df_homless_A2P['mnemonic'].str.startswith('E09')]\n",
    "\n",
    "\n",
    "\n",
    "#print(df_homless_A2P_London.head())\n",
    "#df_homless_A2P_London.shape\n",
    "#df_homless_A2P.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747b793b-eeb1-4788-ab87-a1cf9b788886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353aad63-4418-438f-892e-f8fbfbb81dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27edbba4-318c-4dc7-ad3b-dfd449b635cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE HOUSING CORE DATAFRAMES AND CREATE NEW VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "727c5108-649c-4e92-b3bc-29c3a8c9de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(df_censusdwellings,df_censusHHolds, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge2 = pd.merge(merge1, df_vacantprops, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge3 = pd.merge(merge2, df_median_London, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge4 = pd.merge(merge3, df_lower_London, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge5 = pd.merge(merge4, df_homless_A2P_London, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge6 = pd.merge(merge5, df_hp_totals, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge7 = pd.merge(merge6, df_hp_firsttime_London_totals, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merge8 = pd.merge(merge7, df_hp_newbuild_London_London_totals, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "df_CoreHousing = pd.merge(merge8, df_censusTenure, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "\n",
    "\n",
    "\n",
    "df_CoreHousing['PrevDutyPercent'] = ((df_CoreHousing['HHoldsPrevDuty']) / (df_CoreHousing['Total_Hholds']))*100\n",
    "df_CoreHousing['EndASTPercent'] = ((df_CoreHousing['HHoldEndAST']) / (df_CoreHousing['Total_Hholds']))*100\n",
    "df_CoreHousing['SellReletPercent'] = ((df_CoreHousing['HHoldSellRelet']) / (df_CoreHousing['Total_Hholds']))*100\n",
    "df_CoreHousing['VacantPercent'] = ((df_CoreHousing['2023_LTVacant']) / (df_CoreHousing['Total_Dwellings']))*100\n",
    "\n",
    "#df_CoreHousing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225c30c-5877-455b-aef0-06533c244dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MERGE CENSUS CORE DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "b6c30d5e-0963-470b-99b2-2d13b28de5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mergea = pd.merge(df_censusdwellings,df_censusHHolds, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "mergeb = pd.merge(mergea,df_censusTenure, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "mergec = pd.merge(mergeb,df_censuspopdens, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "merged = pd.merge(mergec,df_censusaddress, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "mergee = pd.merge(merged,df_censuscarsvans, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "mergef = pd.merge(mergee,df_censusdepriv, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "mergeg = pd.merge(mergef,df_censusnssec, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "mergeh = pd.merge(mergeg,df_censusbedocc, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "dfCoreDemographics = pd.merge(mergeh,df_censusaccomm, left_on =\"mnemonic\", right_on = \"mnemonic\")\n",
    "\n",
    "#dfCoreDemographics\n",
    "#mergei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d17c3c8-0d74-4dfa-80f7-fc0a13e94ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918ed9e-23d3-4f8a-ae18-19961591eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix - Core Housing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "8ca21663-7f17-48f4-a389-f4801a787daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CorrDemographics = dfCoreDemographics.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "06896685-cbcf-49c7-84c2-703e8be0180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CorrHousing = df_CoreHousing.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ade6b-c8b3-4b6b-81dc-41a1148dfad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a27c03-deb4-40f0-9f09-f934737b62a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
